{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Objective\n",
    "This exercise revolves around translating a given SQL query into a Python script. The query in question is the ams.rules_input.sql query. \n",
    "\n",
    "**The objective is to generate an exact copy, in a pandas DataFrame, of the ams.sf_cases_input table in Python.**\n",
    "\n",
    "---\n",
    "# 0) Setting Key Variables\n",
    "To start, we're going to perform a toy example that will primarily walk you through accessing the data and provide context and business background.\n",
    "\n",
    "## Context\n",
    "\n",
    "### What is AMS?\n",
    "**AMS is our Asset Management System.** It is the data pipeline run daily that creates the \"master location table\" most of our business uses for device location and status.\n",
    "\n",
    "### What is the Business Value of this Toy Query?\n",
    "The ams.rules_input.sql query creates variables and values for later use by other queries. This was a work-around, analyst-implemented creation in a world that could only use SQL and Redshift.\n",
    "\n",
    "### Important Notes\n",
    "- **The source code is production code - for this exercise, subsets of the tables have been created within the data_engineer schema in the interview database.** \n",
    "    - They are named appropriately: ams.rules_input --> data_engineer.ams_rules_input.\n",
    "\n",
    "### The Query Code\n",
    "The code you will be \"translating\" from SQL to Python is below:\n",
    "\n",
    "```sql\n",
    "DROP TABLE IF EXISTS ams.rules_input;\n",
    "SELECT 'Rollforward date' AS rule, (SELECT value FROM ams.temp)::varchar AS value INTO ams.rules_input UNION ALL --Change to produce AMS for another date. Represents the start of day date (i.e. equates to end of day for date prior). Therefore for end of month use '01-##-20##' not '31-##-20##'.\n",
    "SELECT 'Length of mac address', '12' UNION ALL --The length of a true mac address once stripped for ':'. Shouldn't ever change but is in here incase it does\n",
    "SELECT 'Days from ''In Transit To Member'' Until ''Unknown''', '35' UNION ALL\n",
    "SELECT 'Days from ''In Transit To Warehouse'' Until ''Unknown''', '55' UNION ALL\n",
    "SELECT 'Days from ''X'' Until ''Unknown'' Given No Ping', '45' UNION ALL -- A year from no ping to changing status to Unknown\n",
    "SELECT 'Days from ''Unknown'' Until Netsuite Disposed', '180' UNION ALL -- Six months from being in Unknown to being retired in Netsuite\n",
    "SELECT 'Team name of account owners for accounts undergoing installation', 'Onboarding' UNION ALL\n",
    "SELECT 'Currently Running', (SELECT value FROM ams.temp)::varchar;\n",
    "```\n",
    "\n",
    "### Input Tables\n",
    "- **None:** However, in later examples, and in the exercise itself, this will have the necessary input tables and short descriptions of them.\n",
    "\n",
    "### Output Tables\n",
    "- **ams.rules_input:** A table that contains various business parameters business users can change. In the absence of named variables (and because AMS was built from an analyst's point of view, where SQL and Redshift were the only infrastructure possibilities), this is how parameters are created for AMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the Data\n",
    "### Accessing the Input Data\n",
    "Before any analysis or processing, we need to access the data. Normally, we would use Outcome Health's custom data-pipeline-utils package, which allows us to access data from any of our data stores with the same interface. However, for legal reasons, we'll be using a cleaned subset of data in our interviewing database for pull what we need instead.\n",
    "\n",
    "**In this case, there is no input data to pull, so we'll skip this step for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "\n",
    "pd.options.display.max_colwidth = 200 \n",
    "\n",
    "if False:\n",
    "    conn = psycopg2.connect(host=\"\",\n",
    "                            port=\"\",\n",
    "                            database=\"\", \n",
    "                            user=\"\", \n",
    "                            password=\"\")\n",
    "    sql = \"select count(*) from my_table;\"\n",
    "    data = sqlio.read_sql_query(sql, conn)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Output Data\n",
    "We will, however, want to be able to compare our generated dataframes with the dataframe from the output table. To do that, we'll need to pull the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rule</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Currently Running</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Days from 'In Transit To Member' Until 'Unknown'</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Days from 'In Transit To Warehouse' Until 'Unknown'</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Days from 'Unknown' Until Netsuite Disposed</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Days from 'X' Until 'Unknown' Given No Ping</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Length of mac address</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Rollforward date</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Team name of account owners for accounts undergoing installation</td>\n",
       "      <td>Onboarding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                              rule  \\\n",
       "0   4                                                 Currently Running   \n",
       "1   1                  Days from 'In Transit To Member' Until 'Unknown'   \n",
       "2   6               Days from 'In Transit To Warehouse' Until 'Unknown'   \n",
       "3   3                       Days from 'Unknown' Until Netsuite Disposed   \n",
       "4   2                       Days from 'X' Until 'Unknown' Given No Ping   \n",
       "5   5                                             Length of mac address   \n",
       "6   0                                                  Rollforward date   \n",
       "7   7  Team name of account owners for accounts undergoing installation   \n",
       "\n",
       "        value  \n",
       "0        None  \n",
       "1          35  \n",
       "2          55  \n",
       "3         180  \n",
       "4          45  \n",
       "5          12  \n",
       "6  2019-03-31  \n",
       "7  Onboarding  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(host=\"data-interview.outcomehealth.io\",\n",
    "                        port=\"5432\",\n",
    "                        database=\"product_analytics\", \n",
    "                        user=\"pa_candidate\", \n",
    "                        password=\"OsOntUnDleYeTivi\")\n",
    "\n",
    "rules_sql = \"select id, rule, value from data_engineer.ams_rules_input;\"\n",
    "rules_data = sqlio.read_sql_query(rules_sql, conn)\n",
    "rules_data.sort_values('rule',inplace=True)\n",
    "rules_data.reset_index(drop=True,inplace=True)\n",
    "rules_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "This is where we perform data transformations and merges necessary to reach our output table. \n",
    "\n",
    "In this case, we will be setting all \"rules\" as variables, rather than rebuilding the table. Since the purpose of the table was to set variables, and we can actually do that in Python, that's what we're going to do.\n",
    "\n",
    "**Moving forward, the objective will be to produce an exact replica of the output table - as will be shown below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "today = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d') \n",
    "\n",
    "currently_running = ''                     # A flag for ensuring duplicate AMS processes are not running\n",
    "days_from_in_transit_member_til_unk = 35   # If we do not see a device at a clinic after 35 days after sending it there, it becomes \"unknown\"\n",
    "days_in_transit_ware_til_unk = 55          # If we do not see a device after 55 days after sending it to the warehouse, it becomes \"unknown\"\n",
    "days_from_unk_til_netsuite_disposed = 180  # After a device is \"unknown\" for 180 days, our accounting team writes it off\n",
    "days_from_x_til_unk = 45                   # After a device has been installed, if it does not ping for 45 days, it becomes \"unknown\"\n",
    "mac_address_len = 12                       # The appropriate length of mac addresses\n",
    "rollforward_date = today                   # The date AMS is generating data for\n",
    "team_name = 'Onboarding'                   # The team name of account owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Validation\n",
    "In this case, I'm simply validating that every value is identical to the output table.\n",
    "\n",
    "**Moving forward, I'll be using the pandas.DataFrame.equals method to check that every value is identical.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None does not match.\n",
      "2019-03-31 does not match.\n"
     ]
    }
   ],
   "source": [
    "variables = [currently_running, days_from_in_transit_member_til_unk, days_in_transit_ware_til_unk, \n",
    "             days_from_unk_til_netsuite_disposed, days_from_x_til_unk, mac_address_len, rollforward_date,\n",
    "             team_name]\n",
    "ok = True\n",
    "for n,i in enumerate(rules_data['value']):\n",
    "    if str(variables[n]) != i:\n",
    "        ok = False\n",
    "        print('{} does not match.'.format(i))\n",
    "if ok:\n",
    "    print('Everything is ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1) A Complete Example\n",
    "Now, we'll walk through what a proper example will look like. The exercise you'll be completing will look exactly like this one, with more complex logic.\n",
    "\n",
    "## Context\n",
    "\n",
    "### What is the Business Value of this Toy Query?\n",
    "The ams.sf_cases_input.sql query creates a processes our raw \"cases\" data in Salesforce to create a processed table. \"Cases\" are usually problem devices that we need to address - our Network Operation Solutions team handles calling in to clinics or sending out technicians to get these devices fixed.\n",
    "\n",
    "### The Query Code\n",
    "The code you will be \"translating\" from SQL to Python is below:\n",
    "\n",
    "```sql\n",
    "DROP TABLE IF EXISTS ams.sf_cases_input CASCADE;\n",
    "SELECT\n",
    "    TRIM(UPPER(ISNULL(tablets_impacted,CASE WHEN subject_parse ~ '^[0-9]+$' THEN subject_parse END))) AS asset_tag\n",
    "  ,\tproduct\n",
    "  ,\tMIN(created_date)::date AS first_seen_in_data_date\n",
    "\n",
    "INTO ams.sf_cases_input\n",
    "FROM (\n",
    "    SELECT\n",
    "        tablets_impacted\n",
    "      ,\tLEFT(REPLACE(REPLACE(subject,'(Scheduled) ',''),'Player asset ',''),5) AS subject_parse\n",
    "      ,\tcreated_date\n",
    "      ,\tCASE WHEN case_type ILIKE '%Player%' THEN 'Waiting Room Screen'\n",
    "           WHEN case_type ILIKE '%Tablet%' THEN 'Tablet'\n",
    "           WHEN case_type ILIKE '%Wallboard%' THEN 'Wallboard'\n",
    "           WHEN case_type ILIKE 'Irt %' THEN 'Tablet'\n",
    "           WHEN case_type ILIKE '%WIFI%' THEN 'Waiting Room Wifi'\n",
    "        END AS product\n",
    "\n",
    "    FROM salesforce.cases\n",
    "\n",
    "    WHERE case_type LIKE '%MIA%'\n",
    "   ) a\n",
    "\n",
    "GROUP BY\n",
    "    1,2;\n",
    "```\n",
    "\n",
    "### Input Tables\n",
    "- **salesforce.cases:** The most recently ingested snapshot of the \"cases\" object in Salesforce. Contains metadata about every case that has ever been opened.\n",
    "\n",
    "### Output Tables\n",
    "- **ams.sf_cases_input:** A cleaned up version of a slice of salesforce.cases data - meant for use in our AMS process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the Data\n",
    "### Accessing the Input Data\n",
    "As before, we're going to access the core dataset. I'm only pulling the fields used, for obvious speed reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tablets_impacted</th>\n",
       "      <th>subject</th>\n",
       "      <th>created_date</th>\n",
       "      <th>case_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32302</td>\n",
       "      <td>Player-bs MIA 32302</td>\n",
       "      <td>2018-01-02 13:27:21</td>\n",
       "      <td>Player MIA in BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t103695</td>\n",
       "      <td>Tablet MIA t103695</td>\n",
       "      <td>2018-01-02 13:20:32</td>\n",
       "      <td>Tablet MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t01e103160</td>\n",
       "      <td>Tablet MIA t01e103160</td>\n",
       "      <td>2018-01-02 13:21:01</td>\n",
       "      <td>Tablet MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17604</td>\n",
       "      <td>Player-bs MIA 17604</td>\n",
       "      <td>2018-01-02 13:27:21</td>\n",
       "      <td>Player MIA in BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahtlg0000783858019</td>\n",
       "      <td>Tablet MIA ahtlg0000783858019</td>\n",
       "      <td>2018-01-02 13:14:41</td>\n",
       "      <td>Tablet MIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tablets_impacted                        subject        created_date  \\\n",
       "0               32302            Player-bs MIA 32302 2018-01-02 13:27:21   \n",
       "1             t103695             Tablet MIA t103695 2018-01-02 13:20:32   \n",
       "2          t01e103160          Tablet MIA t01e103160 2018-01-02 13:21:01   \n",
       "3               17604            Player-bs MIA 17604 2018-01-02 13:27:21   \n",
       "4  ahtlg0000783858019  Tablet MIA ahtlg0000783858019 2018-01-02 13:14:41   \n",
       "\n",
       "          case_type  \n",
       "0  Player MIA in BS  \n",
       "1        Tablet MIA  \n",
       "2        Tablet MIA  \n",
       "3  Player MIA in BS  \n",
       "4        Tablet MIA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_sql = '''\n",
    "select \n",
    "   tablets_impacted,\n",
    "   subject,\n",
    "   created_date,\n",
    "   case_type\n",
    "from data_engineer.salesforce_cases\n",
    "where case_type like '%MIA%'\n",
    " AND tablets_impacted not in ('Not Deployed');\n",
    "'''\n",
    "m = sqlio.read_sql_query(cases_sql, conn)\n",
    "cases_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Output Data\n",
    "Again, we want to access the output data in order to compare our result with the real thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asset_tag</th>\n",
       "      <th>product</th>\n",
       "      <th>first_seen_in_data_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T107301</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T01E122281</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>T102121</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AHTLG0000820005056</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41562</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           asset_tag              product first_seen_in_data_date\n",
       "0   0             T107301               Tablet              2018-01-02\n",
       "1   1          T01E122281               Tablet              2018-01-02\n",
       "2   2             T102121               Tablet              2018-01-02\n",
       "3   3  AHTLG0000820005056               Tablet              2018-01-02\n",
       "4   4               41562  Waiting Room Screen              2018-01-02"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sql = '''\n",
    "select \n",
    "    id,\n",
    "    asset_tag,\n",
    "    product,\n",
    "    first_seen_in_data_date\n",
    "from data_engineer.ams_sf_cases_input;\n",
    "'''\n",
    "output_data = sqlio.read_sql_query(output_sql, conn)\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "This is where we perform data transformations and merges necessary to reach our output table. \n",
    "\n",
    "**Again, our objective is to produce an exact replica of the output table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asset_tag                  None\n",
       "product                    None\n",
       "first_seen_in_data_date    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def sort_cases(x):\n",
    "    if 'Player' in x:\n",
    "        return 'Waiting Room Screen'\n",
    "    elif 'Tablet' in x:\n",
    "        return 'Tablet'\n",
    "    elif 'Wallboard' in x:\n",
    "        return 'Wallboard'\n",
    "    elif 'Irt ' == x[:4]:\n",
    "        return 'Tablet'\n",
    "    elif 'WIFI' in x:\n",
    "        return 'Waiting Room Wifi'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def parse_subject(x):\n",
    "    if x:\n",
    "        # Clean Up the string and only select numerical ids\n",
    "        new_str = x.replace('(Scheduled) ','').replace('Player asset ','')[:5]\n",
    "        if re.search('^[0-9]+$',new_str):\n",
    "            return new_str\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_asset_tags(x):\n",
    "    if x:\n",
    "        return x.upper().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the \"Product\" field\n",
    "cases_data['product'] = cases_data['case_type'].apply(sort_cases)\n",
    "cases_data['subject_parse'] = cases_data['subject'].apply(parse_subject)\n",
    "cases_data['asset_tag'] = cases_data['tablets_impacted'].combine_first(cases_data['subject_parse']).apply(clean_asset_tags)\n",
    "cases_data = cases_data[cases_data['product'].notnull()]\n",
    "\n",
    "# We have to fill nulls because otherwise a group by will filter them out\n",
    "cases_data.fillna('None',inplace=True)\n",
    "\n",
    "# Group by and create the \"first_seen_in_date\" field\n",
    "grouped_data = cases_data.groupby(['asset_tag','product'])['created_date'].min()\n",
    "grouped_data = grouped_data.reset_index().rename(columns={'created_date': 'first_seen_in_data_date'})\n",
    "grouped_data['first_seen_in_data_date'] = grouped_data['first_seen_in_data_date'].apply(lambda x: datetime.date(x))\n",
    "grouped_data.replace(to_replace='None',value=None,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the values\n",
    "output_data.sort_values(by=list(output_data.columns),inplace=True)\n",
    "grouped_data.sort_values(by=list(grouped_data.columns),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check that the two dfs are the same length\n",
    "print(len(output_data) == len(grouped_data))\n",
    "\n",
    "# Check that the two dfs have no duplicated columns\n",
    "print(len(output_data) == len(output_data.drop_duplicates(keep=False)))\n",
    "print(len(grouped_data) == len(grouped_data.drop_duplicates(keep=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Validation\n",
    "In this case, I'm simply validating that every value is identical to the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrin.lim/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "grouped_data['name'] = 'grouped'\n",
    "output_data['name'] = 'output'\n",
    "concat_data = pd.concat([grouped_data,output_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_tag</th>\n",
       "      <th>first_seen_in_data_date</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [asset_tag, first_seen_in_data_date, id, name, product]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data.drop_duplicates(subset=['asset_tag','product','first_seen_in_data_date'],keep=False).sort_values(by='asset_tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every row had a duplicate, meaning our two dataframes were exactly the same!! We've achieved our objective!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test Implementation\n",
    "We will ask you to implement at least one unit test to catch errors with your script.\n",
    "\n",
    "In this case, I've implemented a unit test to check that there are no duplicates in our grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dupes_unit_test(grouped_data):\n",
    "    assert len(grouped_data) == len(grouped_data.drop_duplicates(keep=False)), 'We have dupes in our grouped data.'\n",
    "dupes_unit_test(grouped_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
