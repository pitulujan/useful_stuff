{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Objective\n",
    "This exercise revolves around translating a given SQL query into a Python script. The query in question is the ams.rules_input.sql query. \n",
    "\n",
    "**The objective is to generate an exact copy, in a pandas DataFrame, of data_engineer.ams_cms_input_precursor, which is a precursor to the ams.cms_input table in Python.**\n",
    "\n",
    "## Context\n",
    "\n",
    "### What is the Business Value of this Toy Query?\n",
    "The ams.cms_input.sql query aggregates location and status data on our devices. This is required because we have different types of devices that run on different systems - our having multiple systems was an outgrowth of acquisitions (we bought a company called AccentHealth) and the organic creation of new devices (like our WiFi product, which runs on the \"airtight\" system). \"CMS\" stands for ContextMedia Systems, which is how we refer to our systems in their entirety.\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Our objective here is to reproduce the data being inserted into AMS.CMS_INPUT_HISTORY in the second statement below.**\n",
    "\n",
    "- **The source code is production code - for this exercise, subsets of the tables have been created within the data_engineer schema in the interview database.** \n",
    "\n",
    "### The Query Code\n",
    "The code you will be \"translating\" from SQL to Python is below. You may want to paste it somewhere else for easy reading, since the query is fairly long.\n",
    "\n",
    "```sql\n",
    "WITH AMS_AIRTIGHT_SOURCE_SYSTEM_NAMES AS (\n",
    "    SELECT DISTINCT A.SOURCE,\n",
    "                    'at'|| DENSE_RANK() OVER (ORDER BY SOURCE ASC) AS SOURCE_SYSTEM_NAME\n",
    "    FROM data_engineer.airtight_sensors_history A\n",
    "    WHERE A.EXPORT_DATE = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    ")\n",
    "\n",
    "SELECT DISTINCT COALESCE(c.asset_tag, d.asset_tag, a.asset_tag) AS asset_tag,\n",
    "       a.source_system,\n",
    "       a.source_system_id,\n",
    "       a.source_system_asset_name,\n",
    "       COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) AS product,\n",
    "       CASE WHEN a.product_use IN ('Infusion Room Tablet','Rheumatology IRT') AND COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) = 'Tablet' THEN a.product_use ELSE COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) END AS product_use,\n",
    "       a.cmh_id,\n",
    "       a.device_location_status,\n",
    "       a.last_pinged_at,\n",
    "       COALESCE(c.wifi_mac_address,d.wifi_mac_address,d.lan_mac_address,e.wifi_mac_address,e.lan_mac_address,a.mac_address) AS mac_address,\n",
    "       a.ssid,\n",
    "       a.public_ip_address,\n",
    "       COALESCE(c.sku, d.sku, e.sku, f.sku, g.sku, a.sku) AS sku,\n",
    "       a.created_at,\n",
    "       a.installed_date,\n",
    "       a.deleted_at,\n",
    "       a.reason_for_deletion,\n",
    "       a.export_date\n",
    "FROM (\n",
    "    SELECT\n",
    "            TRIM(UPPER(CASE WHEN d.asset_tag IS NOT NULL AND a.asset_id ~ '^A[0-9]+$' THEN a.asset_id --If the airtight name is good then use it\n",
    "                    ELSE COALESCE(d.asset_tag,a.asset_id) --Else use the salesforce/airtight name. If not airtight use CMS name\n",
    "                   END)) AS asset_tag\n",
    "        ,   CASE WHEN cms_column = 'client_id' THEN 'mdm'\n",
    "                 WHEN cms_column = 'radio_macaddress' THEN d.source_system_name\n",
    "                 WHEN cms_column = 'display_unit_id' THEN 'broadsign'\n",
    "            END AS source_system\n",
    "        ,   CASE WHEN cms_column = 'client_id' THEN b.device_id\n",
    "                 WHEN cms_column = 'radio_macaddress' THEN d.boxid\n",
    "                 WHEN cms_column = 'display_unit_id' THEN c.host_id\n",
    "            END AS source_system_id\n",
    "        ,   a.asset_name AS source_system_asset_name\n",
    "        ,   CASE  WHEN a.type IN ('Infusion Room Tablet','Rheumatology IRT') THEN 'Tablet'\n",
    "                  ELSE a.type\n",
    "            END AS product\n",
    "        ,   a.type AS product_use\n",
    "        ,   a.cmh_id\n",
    "        ,   CASE WHEN a.status = 'Active' THEN 'Installed'\n",
    "                 WHEN b.deleted_at IS NOT NULL THEN 'Deleted'\n",
    "                 WHEN b.status = 'Demo' THEN 'Demo'\n",
    "                 ELSE NULL::varchar\n",
    "            END AS device_location_status\n",
    "        ,   a.last_pinged_at\n",
    "        ,   REPLACE(TRIM(UPPER(COALESCE(COALESCE(b.mac_address, b.missing_mac_address),c.mac_address,d.radio_macaddress))),':','') AS mac_address\n",
    "        ,   b.ssid\n",
    "        ,   c.public_ip AS public_ip_address\n",
    "        ,   COALESCE(b.sku,c.sku,d.sku) AS sku\n",
    "        ,   b.created_at\n",
    "        ,   b.installed_date\n",
    "        ,   b.deleted_at\n",
    "        ,   CASE WHEN b.deleted_at IS NOT NULL THEN 'Deleted by membership' END::varchar(250) AS reason_for_deletion\n",
    "        ,   a.export_date\n",
    "\n",
    "    FROM data_engineer.shared_assets_history a\n",
    "\n",
    "    LEFT JOIN (\n",
    "                SELECT\n",
    "                        a.*\n",
    "                    ,   COALESCE(c.sku, b.sku) AS sku\n",
    "                    ,   d.mac_address as missing_mac_address\n",
    "\n",
    "                FROM data_engineer.mdm_devices_history a\n",
    "\n",
    "                LEFT JOIN\n",
    "                (\n",
    "                 SELECT DISTINCT UPPER(a.asset_tag) AS ASSET_TAG,\n",
    "                                 FIRST_VALUE(a.sku) OVER(PARTITION BY a.asset_tag ORDER BY a.created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                   FROM data_engineer.ams_sf_assets_input a\n",
    "                ) b ON UPPER(a.asset_id) = b.asset_tag\n",
    "\n",
    "                LEFT JOIN data_engineer.shared_mdm_custom_rom_sku_mapping c\n",
    "                ON a.custom_rom_version = c.custom_rom_version\n",
    "\n",
    "                LEFT JOIN data_engineer.mdm_missing_mac_addresses d    -- Some duplicate records for assets in MDM with one of which not having a MAC address, make sure that gets assigned so can be flagged as dupe\n",
    "                ON a.asset_id = d.asset_id\n",
    "\n",
    "                WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "              ) b\n",
    "         ON a.cms_id = b.client_id\n",
    "        AND a.export_date = b.export_date\n",
    "        AND a.cms_column = 'client_id'\n",
    "\n",
    "    LEFT JOIN (\n",
    "                SELECT\n",
    "                        a.name\n",
    "                    ,   a.display_unit_id\n",
    "                    ,   b.poll_last_utc AS last_pinged_at\n",
    "                    ,   a.host_id\n",
    "                    ,   COALESCE(a.primary_mac_address,a.secondary_mac_address) AS mac_address\n",
    "                    ,   b.public_ip\n",
    "                    ,   COALESCE(NULLIF(c.sku,'Player'), CASE WHEN a.secondary_mac_address IS NOT NULL THEN 'P-PLA-102-NWA-01' ELSE 'P-PLA-101-NWA-01' END) AS sku --At the time of coding this was the only way to ascertain SKU from broadsign\n",
    "                    ,   a.export_date\n",
    "\n",
    "                FROM data_engineer.broadsign_hosts_history a\n",
    "\n",
    "                LEFT JOIN data_engineer.broadsign_monitor_polls_history b\n",
    "                ON a.host_id = b.client_resource_id\n",
    "                AND a.export_date = b.export_date\n",
    "\n",
    "                LEFT JOIN\n",
    "                (\n",
    "                 SELECT DISTINCT TRIM(UPPER(REPLACE(mac_address,':',''))) AS mac_address,\n",
    "                                 FIRST_VALUE(a.sku) OVER(PARTITION BY mac_address ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                   FROM data_engineer.ams_sf_assets_input a\n",
    "                ) c ON TRIM(UPPER(REPLACE(COALESCE(a.primary_mac_address,a.secondary_mac_address),':',''))) = c.mac_address\n",
    "\n",
    "                LEFT JOIN data_engineer.ams_broadsign_migration_devices_history d\n",
    "                ON a.host_id = cast(d.bs_host_id as bigint)\n",
    "                AND a.export_date = d.export_date\n",
    "\n",
    "                WHERE d.bs_host_id IS NULL\n",
    "                  AND a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "             ) c --It was a mistake to make the cms_id for broadsign display_unit_it but now I need to live with it. Therefore the below complex join is required. Once we move to ods.devices most of these joins after the FROM will not be necessary\n",
    "        ON a.asset_name = c.name\n",
    "        AND a.cms_id = cast(c.display_unit_id as varchar)\n",
    "        AND a.export_date = c.export_date\n",
    "        AND COALESCE(a.last_pinged_at,'1900-01-01') = COALESCE(c.last_pinged_at,'1900-01-01')\n",
    "        AND a.cms_column = 'display_unit_id'\n",
    "\n",
    "    LEFT JOIN (\n",
    "              SELECT DISTINCT\n",
    "                        FIRST_VALUE(a.boxid) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC ROWS UNBOUNDED PRECEDING) AS boxid\n",
    "                    ,   FIRST_VALUE(b.source_system_name) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS source_system_name\n",
    "                    ,   a.export_date\n",
    "                    ,   FIRST_VALUE(a.radio_macaddress) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS radio_macaddress\n",
    "                    ,   FIRST_VALUE(c.asset_tag) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS asset_tag\n",
    "                    ,   FIRST_VALUE(COALESCE(c.sku,'P-WFI-101-MOJ-01')) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS sku\n",
    "\n",
    "                FROM data_engineer.airtight_sensors_history a\n",
    "\n",
    "                INNER JOIN ams_airtight_source_system_names b\n",
    "                ON a.source = b.source\n",
    "\n",
    "                LEFT JOIN\n",
    "                (\n",
    "                    SELECT DISTINCT TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) AS mac_address,\n",
    "                                    FIRST_VALUE(a.asset_tag) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as asset_tag,\n",
    "                                    FIRST_VALUE(a.sku) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                      FROM data_engineer.ams_sf_assets_input a\n",
    "                ) c\n",
    "                ON TRIM(UPPER(REPLACE(a.radio_macaddress,':',''))) = c.mac_address\n",
    "\n",
    "                WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "                ) d\n",
    "    ON a.cms_id = d.radio_macaddress\n",
    "    AND a.export_date = d.export_date\n",
    "    AND a.cms_column = 'radio_macaddress'\n",
    "\n",
    "    WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "    ) a\n",
    "\n",
    "LEFT JOIN data_engineer.ams_cms_input_history b --Ensure this is unique by source_system, source_system_id, export_date\n",
    "ON a.source_system = b.source_system\n",
    "AND a.source_system_id = b.source_system_id\n",
    "AND a.export_date = b.export_date\n",
    "\n",
    "LEFT JOIN data_engineer.ams_bat_input c\n",
    "ON a.mac_address = c.wifi_mac_address\n",
    "\n",
    "LEFT JOIN data_engineer.ams_bat_input d\n",
    "ON a.mac_address = d.lan_mac_address\n",
    "\n",
    "LEFT JOIN data_engineer.ams_bat_input e\n",
    "ON a.asset_tag = e.asset_tag\n",
    "AND a.product = e.product\n",
    "AND a.mac_address IS NULL\n",
    "\n",
    "LEFT JOIN data_engineer.shared_sku_master f\n",
    "ON a.sku = f.sku\n",
    "\n",
    "LEFT JOIN data_engineer.shared_sku_master g\n",
    "ON a.sku = g.old_sku\n",
    "AND g.rollup_sku_to_use\n",
    "\n",
    "WHERE b.source_system_id IS NULL\n",
    "  and a.source_system_asset_name NOT IN ('\\nT17105') -- custom addition for the exercise\n",
    "```\n",
    "\n",
    "### Input Tables\n",
    "#### Airtight Tables: WiFi Router Product Tables\n",
    "- **data_engineer.airtight_sensors_history:** A table containing device location and status data on our WiFi router product. Provides hourly snapshots.\n",
    "\n",
    "#### AMS Tables: Pre-Created Tables Used Specifically for AMS\n",
    "- **data_engineer.ams_bat_input:** - A “seed” table containing a list of devices and device information. Stands for “Big Ass Table”.\n",
    "- **data_engineer.ams_broadsign_migration_devices_history:** Currently an empty table awaiting data for a migration - we’re converting all our Waiting Room TV products to Broadsign (a small subsegment of them were not on Broadsign previously).\n",
    "- **data_engineer.ams_cms_input_history:** A table containing a historical record of daily snapshots of ams.cms_input.\n",
    "- **data_engineer.ams_rules_input:** A table that contains various business parameters business users can change. In the absence of named variables (and because AMS was built from an analyst's point of view, where SQL and Redshift were the only infrastructure possibilities), this is how parameters are created for AMS.\n",
    "- **data_engineer.ams_sf_assets_input:** A generated input table that contains any device information contained in Salesforce. This is primarily for obtaining data on our non-interactive devices, like our TVs.\n",
    "\n",
    "#### Broadsign Tables: Waiting Room TV Product Tables\n",
    "- **data_engineer.broadsign_hosts_history:** Device information on our Waiting Room TV products (the majority of which run on Broadsign - a content delivery platform). \n",
    "- **data_engineer.broadsign_monitor_polls_history:** Ping information on our Waiting Room TV products.\n",
    "\n",
    "#### Mobile Device Management (MDM) Tables: Tables for Device Data on All Other Devices (Tablets and Wallboards)\n",
    "- **data_engineer.mdm_devices_history:** A historical record of information on our devices - MAC address, sku, hardware info, etc.\n",
    "- **data_engineer.mdm_missing_mac_addresses:** A custom table created to identify the MAC address for devices were missing them.\n",
    "\n",
    "#### Shared Tables: Pre-Created Tables in Redshift Used for Multiple Processes, Including AMS\n",
    "- **data_engineer.shared_assets_history:** A legacy table of old asset, product, and status information. We primarily use this as a “seed table” for AMS, which generates a newer version of asset, location, and status information.\n",
    "- **data_engineer.shared_mdm_custom_rom_sku_mapping:** A custom mapping table that helps us determine skus appropriately.\n",
    "- **data_engineer.shared_sku_master:** - Another “seed” table containing manually entered information on sku matching (this was needed to match old skus to newer ones).\n",
    "\n",
    "### Output Tables\n",
    "- **data_engineer.ams_cms_input_precursor:** A precursor to ams.cms_input, which is a cleaned up, aggregated table containing location and status information on our devices - meant for AMS consumption. For our intents and purposes, this is what gets stored in the ams.cms_input_history table as a snapshot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the Data\n",
    "### Accessing the Input Data\n",
    "For speed and optimization reasons, i'm only pulling the required data. For doing so, i went through the SQL query and identified which columns of which tables were needed, and also if there were any \"WHERE\" conditions which would help me reduce the final amount of data that was being downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_colwidth = 200 \n",
    "\n",
    "#Creating connection to the database\n",
    "conn = psycopg2.connect(host=\"data-interview.outcomehealth.io\",\n",
    "                        port=\"5432\",\n",
    "                        database=\"product_analytics\", \n",
    "                        user=\"pa_candidate\", \n",
    "                        password=\"OsOntUnDleYeTivi\")\n",
    "\n",
    "# Getting all the required data into pandas dataframes\n",
    "query_airtight_sensors_history=\"SELECT boxid,radio_macaddress,export_date,export_hour,radio_upsince,source FROM data_engineer.airtight_sensors_history WHERE EXPORT_DATE = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\n",
    "airtight_sensors_history = sqlio.read_sql_query(query_airtight_sensors_history, conn)\n",
    "\n",
    "query_ams_rules_input='SELECT value,rule FROM data_engineer.ams_rules_input'\n",
    "ams_rules_input = sqlio.read_sql_query(query_ams_rules_input,conn)\n",
    "\n",
    "query_ams_bat_input='SELECT wifi_mac_address,lan_mac_address,asset_tag,product,sku FROM data_engineer.ams_bat_input'\n",
    "ams_bat_input = sqlio.read_sql_query(query_ams_bat_input,conn)\n",
    "\n",
    "query_shared_sku_master='SELECT sku,old_sku,rollup_sku_to_use,product FROM data_engineer.shared_sku_master' \n",
    "shared_sku_master = sqlio.read_sql_query(query_shared_sku_master,conn)\n",
    "\n",
    "query_shared_assets_history=\"SELECT asset_id,asset_name,type,status,cmh_id,last_pinged_at,export_date,cms_id,cms_column FROM data_engineer.shared_assets_history WHERE export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date') AND asset_name NOT IN ('\\nT17105')\"\n",
    "shared_assets_history = sqlio.read_sql_query(query_shared_assets_history,conn)\n",
    "\n",
    "query_mdm_devices_history=\"SELECT id,asset_id,custom_rom_version,device_id,client_id,status,mac_address,ssid,created_at,installed_date,deleted_at,export_date FROM data_engineer.mdm_devices_history WHERE export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\n",
    "mdm_devices_history = sqlio.read_sql_query(query_mdm_devices_history,conn)\n",
    "\n",
    "query_ams_sf_assets_input='SELECT asset_tag,sku,created_date,serial_number,mac_address FROM data_engineer.ams_sf_assets_input'\n",
    "ams_sf_assets_input = sqlio.read_sql_query(query_ams_sf_assets_input,conn)\n",
    "\n",
    "query_shared_mdm_custom_rom_sku_mapping='SELECT custom_rom_version,sku FROM data_engineer.shared_mdm_custom_rom_sku_mapping'\n",
    "shared_mdm_custom_rom_sku_mapping = sqlio.read_sql_query(query_shared_mdm_custom_rom_sku_mapping,conn)\n",
    "\n",
    "query_mdm_missing_mac_addresses='SELECT asset_id,mac_address FROM data_engineer.mdm_missing_mac_addresses'\n",
    "mdm_missing_mac_addresses = sqlio.read_sql_query(query_mdm_missing_mac_addresses,conn)\n",
    "\n",
    "query_broadsign_hosts_history=\"SELECT name,display_unit_id,host_id,primary_mac_address,secondary_mac_address,export_date FROM data_engineer.broadsign_hosts_history WHERE export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\n",
    "broadsign_hosts_history = sqlio.read_sql_query(query_broadsign_hosts_history,conn)\n",
    "\n",
    "query_broadsign_monitor_polls_history='SELECT poll_last_utc,public_ip,client_resource_id,export_date FROM data_engineer.broadsign_monitor_polls_history'\n",
    "broadsign_monitor_polls_history = sqlio.read_sql_query(query_broadsign_monitor_polls_history,conn)\n",
    "\n",
    "query_ams_broadsign_migration_devices_history='SELECT bs_host_id,export_date FROM data_engineer.ams_broadsign_migration_devices_history WHERE bs_host_id IS NULL'\n",
    "ams_broadsign_migration_devices_history = sqlio.read_sql_query(query_ams_broadsign_migration_devices_history,conn)\n",
    "\n",
    "query_ams_cms_input_history='SELECT source_system,source_system_id,export_date FROM data_engineer.ams_cms_input_history WHERE source_system_id IS NULL'\n",
    "ams_cms_input_history = sqlio.read_sql_query(query_ams_cms_input_history,conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Output Data\n",
    "For accessing the output dataset, i just run the whole query replacing the **ams_airtight_source_system_names** table into the query for it's definition (inner join line 132) . This will give me the the data i need to compare my results later on, once i have done everything that is required to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_tag</th>\n",
       "      <th>source_system</th>\n",
       "      <th>source_system_id</th>\n",
       "      <th>source_system_asset_name</th>\n",
       "      <th>product</th>\n",
       "      <th>product_use</th>\n",
       "      <th>cmh_id</th>\n",
       "      <th>device_location_status</th>\n",
       "      <th>last_pinged_at</th>\n",
       "      <th>mac_address</th>\n",
       "      <th>ssid</th>\n",
       "      <th>public_ip_address</th>\n",
       "      <th>sku</th>\n",
       "      <th>created_at</th>\n",
       "      <th>installed_date</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>reason_for_deletion</th>\n",
       "      <th>export_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0505</td>\n",
       "      <td>broadsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0505 - Aopen Retired 10/28/13</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-05-01 16:43:38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0516</td>\n",
       "      <td>broadsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0516-1 (WIll be MIA often) - lost/stolen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-10-06 13:20:37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10005</td>\n",
       "      <td>broadsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0501-1_10005</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>501.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-06-26 19:44:16</td>\n",
       "      <td>00018068E25D</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>P-PLA-101-NWA-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10016</td>\n",
       "      <td>broadsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5056-2_10016 - MS /66856/  - Returning 03/18/2016</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>5056.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-11-20 02:30:47</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10021</td>\n",
       "      <td>broadsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30180-1_10021 - Combo</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>Waiting Room Screen</td>\n",
       "      <td>30180.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-04-17 15:00:22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_tag source_system  source_system_id  \\\n",
       "0      0505     broadsign               NaN   \n",
       "1      0516     broadsign               NaN   \n",
       "2     10005     broadsign               NaN   \n",
       "3     10016     broadsign               NaN   \n",
       "4     10021     broadsign               NaN   \n",
       "\n",
       "                            source_system_asset_name              product  \\\n",
       "0                      0505 - Aopen Retired 10/28/13  Waiting Room Screen   \n",
       "1           0516-1 (WIll be MIA often) - lost/stolen  Waiting Room Screen   \n",
       "2                                       0501-1_10005  Waiting Room Screen   \n",
       "3  5056-2_10016 - MS /66856/  - Returning 03/18/2016  Waiting Room Screen   \n",
       "4                              30180-1_10021 - Combo  Waiting Room Screen   \n",
       "\n",
       "           product_use   cmh_id device_location_status      last_pinged_at  \\\n",
       "0  Waiting Room Screen      NaN                   None 2013-05-01 16:43:38   \n",
       "1  Waiting Room Screen      NaN                   None 2008-10-06 13:20:37   \n",
       "2  Waiting Room Screen    501.0                   None 2008-06-26 19:44:16   \n",
       "3  Waiting Room Screen   5056.0                   None 2015-11-20 02:30:47   \n",
       "4  Waiting Room Screen  30180.0                   None 2015-04-17 15:00:22   \n",
       "\n",
       "    mac_address  ssid public_ip_address               sku created_at  \\\n",
       "0          None  None              None              None        NaT   \n",
       "1          None  None              None              None        NaT   \n",
       "2  00018068E25D  None              None  P-PLA-101-NWA-01        NaT   \n",
       "3          None  None              None              None        NaT   \n",
       "4          None  None              None              None        NaT   \n",
       "\n",
       "  installed_date deleted_at reason_for_deletion export_date  \n",
       "0           None        NaT                None  2019-03-31  \n",
       "1           None        NaT                None  2019-03-31  \n",
       "2           None        NaT                None  2019-03-31  \n",
       "3           None        NaT                None  2019-03-31  \n",
       "4           None        NaT                None  2019-03-31  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"SELECT DISTINCT COALESCE(c.asset_tag, d.asset_tag, a.asset_tag) AS asset_tag,\n",
    "       a.source_system,\n",
    "       a.source_system_id,\n",
    "       a.source_system_asset_name,\n",
    "       COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) AS product,\n",
    "       CASE WHEN a.product_use IN ('Infusion Room Tablet','Rheumatology IRT') AND COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) = 'Tablet' THEN a.product_use ELSE COALESCE(c.product, d.product, e.product, f.product, g.product, a.product) END AS product_use,\n",
    "       a.cmh_id,\n",
    "       a.device_location_status,\n",
    "       a.last_pinged_at,\n",
    "       COALESCE(c.wifi_mac_address,d.wifi_mac_address,d.lan_mac_address,e.wifi_mac_address,e.lan_mac_address,a.mac_address) AS mac_address,\n",
    "       a.ssid,\n",
    "       a.public_ip_address,\n",
    "       COALESCE(c.sku, d.sku, e.sku, f.sku, g.sku, a.sku) AS sku,\n",
    "       a.created_at,\n",
    "       a.installed_date,\n",
    "       a.deleted_at,\n",
    "       a.reason_for_deletion,\n",
    "       a.export_date\n",
    "FROM (\n",
    "    SELECT\n",
    "            TRIM(UPPER(CASE WHEN d.asset_tag IS NOT NULL AND a.asset_id ~ '^A[0-9]+$' THEN a.asset_id --If the airtight name is good then use it\n",
    "                    ELSE COALESCE(d.asset_tag,a.asset_id) --Else use the salesforce/airtight name. If not airtight use CMS name\n",
    "                   END)) AS asset_tag\n",
    "        ,   CASE WHEN cms_column = 'client_id' THEN 'mdm'\n",
    "                 WHEN cms_column = 'radio_macaddress' THEN d.source_system_name\n",
    "                 WHEN cms_column = 'display_unit_id' THEN 'broadsign'\n",
    "            END AS source_system\n",
    "        ,   CASE WHEN cms_column = 'client_id' THEN b.device_id\n",
    "                 WHEN cms_column = 'radio_macaddress' THEN d.boxid\n",
    "                 WHEN cms_column = 'display_unit_id' THEN c.host_id\n",
    "            END AS source_system_id\n",
    "        ,   a.asset_name AS source_system_asset_name\n",
    "        ,   CASE  WHEN a.type IN ('Infusion Room Tablet','Rheumatology IRT') THEN 'Tablet'\n",
    "                  ELSE a.type\n",
    "            END AS product\n",
    "        ,   a.type AS product_use\n",
    "        ,   a.cmh_id\n",
    "        ,   CASE WHEN a.status = 'Active' THEN 'Installed'\n",
    "                 WHEN b.deleted_at IS NOT NULL THEN 'Deleted'\n",
    "                 WHEN b.status = 'Demo' THEN 'Demo'\n",
    "                 ELSE NULL::varchar\n",
    "            END AS device_location_status\n",
    "        ,   a.last_pinged_at\n",
    "        ,   REPLACE(TRIM(UPPER(COALESCE(COALESCE(b.mac_address, b.missing_mac_address),c.mac_address,d.radio_macaddress))),':','') AS mac_address\n",
    "        ,   b.ssid\n",
    "        ,   c.public_ip AS public_ip_address\n",
    "        ,   COALESCE(b.sku,c.sku,d.sku) AS sku\n",
    "        ,   b.created_at\n",
    "        ,   b.installed_date\n",
    "        ,   b.deleted_at\n",
    "        ,   CASE WHEN b.deleted_at IS NOT NULL THEN 'Deleted by membership' END::varchar(250) AS reason_for_deletion\n",
    "        ,   a.export_date\n",
    "\n",
    "    FROM data_engineer.shared_assets_history a\n",
    "\n",
    "        LEFT JOIN (\n",
    "                    SELECT\n",
    "                            a.*\n",
    "                        ,   COALESCE(c.sku, b.sku) AS sku\n",
    "                        ,   d.mac_address as missing_mac_address\n",
    "\n",
    "                    FROM data_engineer.mdm_devices_history a\n",
    "\n",
    "                        LEFT JOIN (\n",
    "                          \n",
    "                            SELECT DISTINCT UPPER(a.asset_tag) AS ASSET_TAG,\n",
    "                                            FIRST_VALUE(a.sku) OVER(PARTITION BY a.asset_tag ORDER BY a.created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                            FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) b \n",
    "                        ON UPPER(a.asset_id) = b.asset_tag\n",
    "\n",
    "                        LEFT JOIN data_engineer.shared_mdm_custom_rom_sku_mapping c\n",
    "                        ON a.custom_rom_version = c.custom_rom_version\n",
    "\n",
    "                        LEFT JOIN data_engineer.mdm_missing_mac_addresses d    -- Some duplicate records for assets in MDM with one of which not having a MAC address, make sure that gets assigned so can be flagged as dupe\n",
    "                        ON a.asset_id = d.asset_id\n",
    "\n",
    "                    WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "                  ) b\n",
    "            ON a.cms_id = b.client_id\n",
    "            AND a.export_date = b.export_date\n",
    "            AND a.cms_column = 'client_id'\n",
    "\n",
    "        LEFT JOIN (\n",
    "                    SELECT\n",
    "                            a.name\n",
    "                        ,   a.display_unit_id\n",
    "                        ,   b.poll_last_utc AS last_pinged_at\n",
    "                        ,   a.host_id\n",
    "                        ,   COALESCE(a.primary_mac_address,a.secondary_mac_address) AS mac_address\n",
    "                        ,   b.public_ip\n",
    "                        ,   COALESCE(NULLIF(c.sku,'Player'), CASE WHEN a.secondary_mac_address IS NOT NULL THEN 'P-PLA-102-NWA-01' ELSE 'P-PLA-101-NWA-01' END) AS sku --At the time of coding this was the only way to ascertain SKU from broadsign\n",
    "                        ,   a.export_date\n",
    "\n",
    "                    FROM data_engineer.broadsign_hosts_history a\n",
    "\n",
    "                        LEFT JOIN data_engineer.broadsign_monitor_polls_history b\n",
    "                        ON a.host_id = b.client_resource_id\n",
    "                        AND a.export_date = b.export_date\n",
    "\n",
    "                        LEFT JOIN\n",
    "                        (\n",
    "                         SELECT DISTINCT TRIM(UPPER(REPLACE(mac_address,':',''))) AS mac_address,\n",
    "                                         FIRST_VALUE(a.sku) OVER(PARTITION BY mac_address ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                           FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) c \n",
    "                        ON TRIM(UPPER(REPLACE(COALESCE(a.primary_mac_address,a.secondary_mac_address),':',''))) = c.mac_address\n",
    "\n",
    "                        LEFT JOIN data_engineer.ams_broadsign_migration_devices_history d\n",
    "                        ON a.host_id = cast(d.bs_host_id as bigint)\n",
    "                        AND a.export_date = d.export_date\n",
    "\n",
    "                    WHERE d.bs_host_id IS NULL AND a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "                 ) c --It was a mistake to make the cms_id for broadsign display_unit_it but now I need to live with it. Therefore the below complex join is required. Once we move to ods.devices most of these joins after the FROM will not be necessary\n",
    "            ON a.asset_name = c.name\n",
    "            AND a.cms_id = cast(c.display_unit_id as varchar)\n",
    "            AND a.export_date = c.export_date\n",
    "            AND COALESCE(a.last_pinged_at,'1900-01-01') = COALESCE(c.last_pinged_at,'1900-01-01')\n",
    "            AND a.cms_column = 'display_unit_id'\n",
    "\n",
    "        LEFT JOIN (\n",
    "                SELECT DISTINCT\n",
    "                            FIRST_VALUE(a.boxid) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC ROWS UNBOUNDED PRECEDING) AS boxid\n",
    "                        ,   FIRST_VALUE(b.source_system_name) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS source_system_name\n",
    "                        ,   a.export_date\n",
    "                        ,   FIRST_VALUE(a.radio_macaddress) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS radio_macaddress\n",
    "                        ,   FIRST_VALUE(c.asset_tag) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS asset_tag\n",
    "                        ,   FIRST_VALUE(COALESCE(c.sku,'P-WFI-101-MOJ-01')) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS sku\n",
    "\n",
    "                FROM data_engineer.airtight_sensors_history a\n",
    "\n",
    "                    INNER JOIN(\n",
    "                    \t\t\tSELECT DISTINCT A.SOURCE,\n",
    "                    \t\t\t\t\t\t\t'at'|| DENSE_RANK() OVER (ORDER BY SOURCE ASC) AS SOURCE_SYSTEM_NAME\n",
    "    \t\t\t\t\t\t\tFROM data_engineer.airtight_sensors_history A\n",
    "    \t\t\t\t\t\t\tWHERE A.EXPORT_DATE = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')) b\n",
    "                    ON a.source = b.source\n",
    "\n",
    "                    LEFT JOIN(\n",
    "                          SELECT DISTINCT TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) AS mac_address,\n",
    "                                        FIRST_VALUE(a.asset_tag) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as asset_tag,\n",
    "                                        FIRST_VALUE(a.sku) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                          FROM data_engineer.ams_sf_assets_input a\n",
    "                            ) c\n",
    "                    ON TRIM(UPPER(REPLACE(a.radio_macaddress,':',''))) = c.mac_address\n",
    "\n",
    "                WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "\n",
    "                   ) d \n",
    "            ON a.cms_id = d.radio_macaddress\n",
    "            AND a.export_date = d.export_date\n",
    "            AND a.cms_column = 'radio_macaddress'\n",
    "\n",
    "    WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\n",
    "    ) a\n",
    "\n",
    "    LEFT JOIN data_engineer.ams_cms_input_history b --Ensure this is unique by source_system, source_system_id, export_date\n",
    "    ON a.source_system = b.source_system\n",
    "    AND a.source_system_id = b.source_system_id\n",
    "    AND a.export_date = b.export_date\n",
    "\n",
    "    LEFT JOIN data_engineer.ams_bat_input c\n",
    "    ON a.mac_address = c.wifi_mac_address\n",
    "\n",
    "    LEFT JOIN data_engineer.ams_bat_input d\n",
    "    ON a.mac_address = d.lan_mac_address\n",
    "\n",
    "    LEFT JOIN data_engineer.ams_bat_input e\n",
    "    ON a.asset_tag = e.asset_tag\n",
    "    AND a.product = e.product\n",
    "    AND a.mac_address IS NULL\n",
    "\n",
    "    LEFT JOIN data_engineer.shared_sku_master f\n",
    "    ON a.sku = f.sku\n",
    "\n",
    "    LEFT JOIN data_engineer.shared_sku_master g\n",
    "    ON a.sku = g.old_sku\n",
    "    AND g.rollup_sku_to_use\n",
    "\n",
    "WHERE b.source_system_id IS NULL and a.source_system_asset_name NOT IN ('\\nT17105')\"\"\"\n",
    "output_data = sqlio.read_sql_query(sql, conn)\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing the problem\n",
    "\n",
    "The first thing i did to solve this problem was to take some time to break the problem down into smaller pieces. After doing so, i recognized 3 small tables that needed to be created before anything else. These tables are **\"b*\"**,**\"c*\"** and **\"d*\"** (which all together they compose **\"a\"**). Also, there is one table called **\"ams_airtight_source_system_names\"**, which is the very first piece of code that appears in the SQL code, which is used for an inner join later on in the query, the one that generates table **\"d*\"**.\n",
    "\n",
    "As i said, **\"b*\"**,**\"c*\"** and **\"d*\"** compose **\"a\"**, and once i have **\"a\"**, all i have to do is some left joins ( with  **\"b\"**, **\"c\"**, **\"d\"**, **\"e\"**, **\"f\"** and **\"g\"**) to get the final table from which i will take the final data (the first SELECT DISTINCT that one runs into when reading the query), to emulate the result of the SQL query with a pandas dataframe. \n",
    "\n",
    "As a good practice, i prefer validating the results on the go, so every step i take i check if the result i have is the one that im supposed to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "\n",
    "### First things first, getting **\"ams_airtight_source_system_names\":**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty panda dataframe\n",
    "ams_airtight_source_system_names = pd.DataFrame()\n",
    "\n",
    "#Filling in the dataframe with the required data\n",
    "\n",
    "#Creating the 'source' column and filling it with unique values\n",
    "ams_airtight_source_system_names['source'] = airtight_sensors_history['source'].drop_duplicates()\n",
    "\n",
    "#Creating a rank column and passing the returned rank series, concatenating a string 'at' to each row\n",
    "ams_airtight_source_system_names['source_system_name'] ='at'+airtight_sensors_history.source.rank(method='dense').astype('int').astype('str')\n",
    "\n",
    "#Reseting the index and deleting the old one (drop=True)\n",
    "ams_airtight_source_system_names.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both tables are equal!\n"
     ]
    }
   ],
   "source": [
    "#SQL query which returns the 'ams_airtight_source_system_names' table\n",
    "sql = \"\"\"SELECT DISTINCT A.SOURCE,\n",
    "                    'at'|| DENSE_RANK() OVER (ORDER BY SOURCE ASC) AS SOURCE_SYSTEM_NAME\n",
    "    FROM data_engineer.airtight_sensors_history A\n",
    "    WHERE A.EXPORT_DATE = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\"\n",
    "\n",
    "#Fetching the resulting data from the sql query\n",
    "data = sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "# I check if both tables have the same length, and if so i merge them and then locate the rows where the column\n",
    "# \"_merge\" is different from 'both', in other words, if both tables are equal , the dataframe 'foo' will be\n",
    "# empty\n",
    "if len(data) == len(ams_airtight_source_system_names):\n",
    "    foo = data.merge(ams_airtight_source_system_names,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "    if len(foo) == 0:\n",
    "        print(\"Both tables are equal!\")\n",
    "    else:\n",
    "        print(\"Both tables are not equal\")\n",
    "else:\n",
    "    print(\"The lenght of each table is different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting b*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= \"\"\"SELECT\n",
    "                            a.*\n",
    "                        ,   COALESCE(c.sku, b.sku) AS sku\n",
    "                        ,   d.mac_address as missing_mac_address\n",
    "\n",
    "                    FROM data_engineer.mdm_devices_history a\n",
    "\n",
    "                        LEFT JOIN (\n",
    "                          \n",
    "                            SELECT DISTINCT UPPER(a.asset_tag) AS ASSET_TAG,\n",
    "                                            FIRST_VALUE(a.sku) OVER(PARTITION BY a.asset_tag ORDER BY a.created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                            FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) b \n",
    "                        ON UPPER(a.asset_id) = b.asset_tag\n",
    "\n",
    "                        LEFT JOIN data_engineer.shared_mdm_custom_rom_sku_mapping c\n",
    "                        ON a.custom_rom_version = c.custom_rom_version\n",
    "\n",
    "                        LEFT JOIN data_engineer.mdm_missing_mac_addresses d    -- Some duplicate records for assets in MDM with one of which not having a MAC address, make sure that gets assigned so can be flagged as dupe\n",
    "                        ON a.asset_id = d.asset_id\n",
    "\n",
    "                    WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the data in column 'created_date' into datetime.date objects, since i dont know in which data type\n",
    "# the data is, i use try/except \n",
    "\n",
    "try:\n",
    "\tams_sf_assets_input['created_date'] = ams_sf_assets_input['created_date'].apply(lambda x: datetime.date(x))\n",
    "except Exception as e:\n",
    "    # Data already in datetime.date type\n",
    "\tif str(e) == \"descriptor 'date' requires a 'datetime.datetime' object but received a 'datetime.date'\":\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tprint(str(e))\n",
    "\n",
    "#Sorting the dataframe by 'created_date' in descending order\n",
    "ams_sf_assets_input.sort_values(['created_date'],ascending=False,inplace=True)\n",
    "\n",
    "#Filling the NaNs values in 'asset_tag' column with a string 'None' so that the group by doesn't filter \n",
    "#them out\n",
    "ams_sf_assets_input['asset_tag'].fillna('None',inplace=True)\n",
    "\n",
    "#Grouping the dataframe by 'asset_tag' and selecting the first 'sku' value per window \n",
    "b=ams_sf_assets_input.groupby('asset_tag').agg({'sku':'first'}).reset_index()\n",
    "\n",
    "#Parsing the column to upper case (SELECT DISTINCT UPPER(a.asset_tag) AS ASSET_TAG...)\n",
    "b['asset_tag']=b['asset_tag'].str.upper() \n",
    "\n",
    "#Since the first LEFT JOIN uses 'asset_id' from the 'mdm_device_history' as the condition for the join, and\n",
    "#since b uses 'asset_tag', which has already been filled in with 'None' for the NaN values, im parsing the \n",
    "#'asset_id' as well\n",
    "mdm_devices_history['asset_id'].fillna('None',inplace=True)\n",
    "\n",
    "\n",
    "#Getting the 'asset_tag' column to upper case for the \"ON\" condition in the first left join, this wont have\n",
    "#any effects going forward since im not using that column outside this first big \"SELECT\" that compose b*\n",
    "mdm_devices_history['asset_id']=mdm_devices_history['asset_id'].str.upper()\n",
    "\n",
    "#Same reason as above\n",
    "mdm_missing_mac_addresses['asset_id']=mdm_missing_mac_addresses['asset_id'].str.upper()\n",
    "\n",
    "#LEFT JOINS\n",
    "\n",
    "#First left join, im using suffixes in case both tables have any columns with the same name\n",
    "s1 = pd.merge(mdm_devices_history, b, how='left', left_on= ['asset_id'],right_on=['asset_tag'],suffixes=('_a','_b'))\n",
    "\n",
    "\n",
    "s2 = pd.merge(s1, shared_mdm_custom_rom_sku_mapping, how='left', left_on=['custom_rom_version'],right_on=['custom_rom_version'],suffixes=('','_c'))\n",
    "\n",
    "\n",
    "s3 = pd.merge(s2, mdm_missing_mac_addresses, how='left', left_on=['asset_id'],right_on=['asset_id'],suffixes=('','_d'))\n",
    "\n",
    "#Finally getting b* by concatenating s3 columns, since i have a*, which means every column from a, i use \n",
    "#list('mdm_devices_history'). The 'combine_first' emulates the  SQL function 'COALESCE', which returns the \n",
    "#first non-null value from sku_c and sku in this case \n",
    "b=pd.concat([s3[list(mdm_devices_history.columns)],s3.sku_c.combine_first(s3.sku)],axis=1)\n",
    "\n",
    "#Changing names\n",
    "b['missing_mac_address']=s3['mac_address_d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating b*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both tables are equal!\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\" SELECT\n",
    "                            a.*\n",
    "                        ,   COALESCE(c.sku, b.sku) AS sku\n",
    "                        ,   d.mac_address as missing_mac_address\n",
    "\n",
    "                    FROM data_engineer.mdm_devices_history a\n",
    "\n",
    "                        LEFT JOIN (\n",
    "                          \n",
    "                            SELECT DISTINCT UPPER(a.asset_tag) AS ASSET_TAG,\n",
    "                                            FIRST_VALUE(a.sku) OVER(PARTITION BY a.asset_tag ORDER BY a.created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                            FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) b \n",
    "                        ON UPPER(a.asset_id) = b.asset_tag\n",
    "\n",
    "                        LEFT JOIN data_engineer.shared_mdm_custom_rom_sku_mapping c\n",
    "                        ON a.custom_rom_version = c.custom_rom_version\n",
    "\n",
    "                        LEFT JOIN data_engineer.mdm_missing_mac_addresses d    -- Some duplicate records for assets in MDM with one of which not having a MAC address, make sure that gets assigned so can be flagged as dupe\n",
    "                        ON a.asset_id = d.asset_id\n",
    "\n",
    "                    WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\"\n",
    "data = sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "if len(data) == len(b):\n",
    "    #As i explained before, given that i used upper case for the 'asset_tag' column, i need to change it \n",
    "    #as well in the 'data' dataframe, which comes from SQL. This is not gonna be a problem going forward\n",
    "    #because b*['asset_id'] is not being used anywhere else\n",
    "    data['asset_id']=data['asset_id'].str.upper()\n",
    "    foo = data.merge(b,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "    if len(foo) == 0:\n",
    "        print(\"Both tables are equal!\")\n",
    "    else:\n",
    "        print(\"Both tables are not equal\")\n",
    "else:\n",
    "    print(\"The lenght of each table is different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting c*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=\"\"\"SELECT\n",
    "                            a.name\n",
    "                        ,   a.display_unit_id\n",
    "                        ,   b.poll_last_utc AS last_pinged_at\n",
    "                        ,   a.host_id\n",
    "                        ,   COALESCE(a.primary_mac_address,a.secondary_mac_address) AS mac_address\n",
    "                        ,   b.public_ip\n",
    "                        ,   COALESCE(NULLIF(c.sku,'Player'), CASE WHEN a.secondary_mac_address IS NOT NULL THEN 'P-PLA-102-NWA-01' ELSE 'P-PLA-101-NWA-01' END) AS sku --At the time of coding this was the only way to ascertain SKU from broadsign\n",
    "                        ,   a.export_date\n",
    "\n",
    "                    FROM data_engineer.broadsign_hosts_history a\n",
    "\n",
    "                        LEFT JOIN data_engineer.broadsign_monitor_polls_history b\n",
    "                        ON a.host_id = b.client_resource_id\n",
    "                        AND a.export_date = b.export_date\n",
    "\n",
    "                        LEFT JOIN\n",
    "                        (\n",
    "                         SELECT DISTINCT TRIM(UPPER(REPLACE(mac_address,':',''))) AS mac_address,\n",
    "                                         FIRST_VALUE(a.sku) OVER(PARTITION BY mac_address ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                           FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) c \n",
    "                        ON TRIM(UPPER(REPLACE(COALESCE(a.primary_mac_address,a.secondary_mac_address),':',''))) = c.mac_address\n",
    "\n",
    "                        LEFT JOIN data_engineer.ams_broadsign_migration_devices_history d\n",
    "                        ON a.host_id = cast(d.bs_host_id as bigint)\n",
    "                        AND a.export_date = d.export_date\n",
    "\n",
    "                    WHERE d.bs_host_id IS NULL AND a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the NaNs values in 'mac_addres' column with a string 'None' so that the group by doesn't filter \n",
    "#them out\n",
    "ams_sf_assets_input['mac_address'].fillna('None',inplace=True)\n",
    "\n",
    "#Grouping the dataframe by 'asset_tag' and selecting the first 'sku' value per window \n",
    "c=ams_sf_assets_input.groupby('mac_address').agg({'sku':'first'}).reset_index()\n",
    "\n",
    "#LEFT JOINS\n",
    "\n",
    "\n",
    "s1 = pd.merge(broadsign_hosts_history, broadsign_monitor_polls_history, how='left', left_on=['host_id','export_date'],right_on=['client_resource_id','export_date'],suffixes=('_a','_b'))\n",
    "\n",
    "\n",
    "s2 = pd.merge(s1, c, how='left', left_on=[broadsign_hosts_history.primary_mac_address.combine_first(broadsign_hosts_history.secondary_mac_address).str.replace(':','').str.upper().str.strip()],right_on=['mac_address'],suffixes=('','_c'))\n",
    "\n",
    "\n",
    "s3 = pd.merge(s2, ams_broadsign_migration_devices_history, how='left', left_on=[broadsign_hosts_history['host_id'],broadsign_hosts_history['export_date']],right_on=[ams_broadsign_migration_devices_history.bs_host_id.astype('int64'),'export_date'],suffixes=('','_d'))\n",
    "\n",
    "def case(x):\n",
    "    if x == None:\n",
    "        return 'P-PLA-101-NWA-01'\n",
    "    else:\n",
    "        return 'P-PLA-102-NWA-01'\n",
    "\n",
    "def nullif(x):\n",
    "\tif x == 'Player':\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\treturn x\n",
    "\n",
    "#Swapping NaNs for None \n",
    "s3['secondary_mac_address'].fillna('None').replace(to_replace='None',value=None,inplace=True)\n",
    "\n",
    "#Getting c by concatenating s3 columns\n",
    "c=pd.concat([s3[['name','display_unit_id','poll_last_utc','host_id','public_ip','export_date']],s3.primary_mac_address.combine_first(s3.secondary_mac_address)],axis=1)\n",
    "c = c.rename(columns={'poll_last_utc': 'last_pinged_at','primary_mac_address':'mac_address'})\n",
    "\n",
    "s3['sku'].fillna('None').replace(to_replace='None',value=None,inplace=True)\n",
    "c['sku'] = s3['sku'].apply(nullif).combine_first(s3['secondary_mac_address'].apply(case))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating c*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both tables are equal!\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"SELECT\n",
    "                            a.name\n",
    "                        ,   a.display_unit_id\n",
    "                        ,   b.poll_last_utc AS last_pinged_at\n",
    "                        ,   a.host_id\n",
    "                        ,   COALESCE(a.primary_mac_address,a.secondary_mac_address) AS mac_address\n",
    "                        ,   b.public_ip\n",
    "                        ,   COALESCE(NULLIF(c.sku,'Player'), CASE WHEN a.secondary_mac_address IS NOT NULL THEN 'P-PLA-102-NWA-01' ELSE 'P-PLA-101-NWA-01' END) AS sku --At the time of coding this was the only way to ascertain SKU from broadsign\n",
    "                        ,   a.export_date\n",
    "\n",
    "                    FROM data_engineer.broadsign_hosts_history a\n",
    "\n",
    "                        LEFT JOIN data_engineer.broadsign_monitor_polls_history b\n",
    "                        ON a.host_id = b.client_resource_id\n",
    "                        AND a.export_date = b.export_date\n",
    "\n",
    "                        LEFT JOIN\n",
    "                        (\n",
    "                         SELECT DISTINCT TRIM(UPPER(REPLACE(mac_address,':',''))) AS mac_address,\n",
    "                                         FIRST_VALUE(a.sku) OVER(PARTITION BY mac_address ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                           FROM data_engineer.ams_sf_assets_input a\n",
    "                        ) c \n",
    "                        ON TRIM(UPPER(REPLACE(COALESCE(a.primary_mac_address,a.secondary_mac_address),':',''))) = c.mac_address\n",
    "\n",
    "                        LEFT JOIN data_engineer.ams_broadsign_migration_devices_history d\n",
    "                        ON a.host_id = cast(d.bs_host_id as bigint)\n",
    "                        AND a.export_date = d.export_date\n",
    "\n",
    "                    WHERE d.bs_host_id IS NULL AND a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\"\n",
    "data = sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "if len(data) == len(c):\n",
    "    foo = data.merge(c,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "    if len(foo) == 0:\n",
    "        print(\"Both tables are equal!\")\n",
    "    else:\n",
    "        print(\"Both tables are not equal\")\n",
    "else:\n",
    "    print(\"The lenght of each table is different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=\"\"\"SELECT DISTINCT\n",
    "                            FIRST_VALUE(a.boxid) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC ROWS UNBOUNDED PRECEDING) AS boxid\n",
    "                        ,   FIRST_VALUE(b.source_system_name) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS source_system_name\n",
    "                        ,   a.export_date\n",
    "                        ,   FIRST_VALUE(a.radio_macaddress) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS radio_macaddress\n",
    "                        ,   FIRST_VALUE(c.asset_tag) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS asset_tag\n",
    "                        ,   FIRST_VALUE(COALESCE(c.sku,'P-WFI-101-MOJ-01')) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS sku\n",
    "\n",
    "                FROM data_engineer.airtight_sensors_history a\n",
    "\n",
    "                    INNER JOIN ams_airtight_source_system_names b\n",
    "                    ON a.source = b.source\n",
    "\n",
    "                    LEFT JOIN(\n",
    "                          SELECT DISTINCT TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) AS mac_address,\n",
    "                                        FIRST_VALUE(a.asset_tag) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as asset_tag,\n",
    "                                        FIRST_VALUE(a.sku) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                          FROM data_engineer.ams_sf_assets_input a\n",
    "                            ) c\n",
    "                    ON TRIM(UPPER(REPLACE(a.radio_macaddress,':',''))) = c.mac_address\n",
    "\n",
    "                WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_first_str(x):\n",
    "    if x == 'None':\n",
    "        return 'P-WFI-101-MOJ-01'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#ams_sf_assets_input['created_date'] = ams_sf_assets_input['created_date'].apply(lambda x: datetime.date(x))\n",
    "#ams_sf_assets_input.sort_values(['created_date'],ascending=False,inplace=True)\n",
    "\n",
    "ams_sf_assets_input['asset_tag'].fillna('None',inplace=True)\n",
    "\n",
    "c=ams_sf_assets_input.groupby(ams_sf_assets_input['serial_number'].combine_first(ams_sf_assets_input['mac_address']).str.replace(':','').str.upper().str.strip().fillna('None')).agg({'asset_tag':'first','sku':'first'}).reset_index().drop_duplicates()\n",
    "c=c.rename(columns={'serial_number':'mac_address'})\n",
    "\n",
    "\n",
    "airtight_sensors_history['foo']=airtight_sensors_history['radio_macaddress'].str.replace(':','').str.upper().str.strip()\n",
    "airtight_sensors_history['radio_macaddress'].fillna('None',inplace=True)\n",
    "#airtight_sensors_history['export_date'] = airtight_sensors_history['export_date'].apply(lambda x: datetime.date(x)) ya esta en datetime\n",
    "#airtight_sensors_history['radio_upsince'] = airtight_sensors_history['radio_upsince'].apply(lambda x: datetime.date(x))\n",
    "#airtight_sensors_history['export_hour'] = airtight_sensors_history['export_hour'].apply(lambda x: datetime.date(x)) ya esta en datetime\n",
    "\n",
    "s1=pd.merge(airtight_sensors_history,ams_airtight_source_system_names, on='source', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "s2=pd.merge(s1,c,how='left', right_on='mac_address', left_on='foo')\n",
    "\n",
    "s2['sku'].fillna('None',inplace=True)\n",
    "s2['sku']=s2['sku'].apply(combine_first_str)\n",
    "\n",
    "s2.sort_values(['export_hour','radio_upsince'],ascending=[False,False])\n",
    "d=s2.groupby(['radio_macaddress', 'export_date']).agg({'boxid':'first','source_system_name':'first','radio_macaddress':'first','asset_tag':'first','sku':'first'}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both tables are equal!\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"SELECT DISTINCT\n",
    "                            FIRST_VALUE(a.boxid) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC ROWS UNBOUNDED PRECEDING) AS boxid\n",
    "                        ,   FIRST_VALUE(b.source_system_name) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS source_system_name\n",
    "                        ,   a.export_date\n",
    "                        ,   FIRST_VALUE(a.radio_macaddress) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS radio_macaddress\n",
    "                        ,   FIRST_VALUE(c.asset_tag) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS asset_tag\n",
    "                        ,   FIRST_VALUE(COALESCE(c.sku,'P-WFI-101-MOJ-01')) OVER (PARTITION BY a.radio_macaddress, a.export_date ORDER BY a.export_hour DESC, a.radio_upsince DESC  ROWS UNBOUNDED PRECEDING) AS sku\n",
    "\n",
    "                FROM data_engineer.airtight_sensors_history a\n",
    "\n",
    "                    INNER JOIN (    SELECT DISTINCT A.SOURCE,\n",
    "                    'at'|| DENSE_RANK() OVER (ORDER BY SOURCE ASC) AS SOURCE_SYSTEM_NAME\n",
    "    FROM data_engineer.airtight_sensors_history A\n",
    "    WHERE A.EXPORT_DATE = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')) b\n",
    "                    ON a.source = b.source\n",
    "\n",
    "                    LEFT JOIN(\n",
    "                          SELECT DISTINCT TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) AS mac_address,\n",
    "                                        FIRST_VALUE(a.asset_tag) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as asset_tag,\n",
    "                                        FIRST_VALUE(a.sku) OVER(PARTITION BY TRIM(UPPER(REPLACE(COALESCE(serial_number, mac_address),':',''))) ORDER BY created_date DESC ROWS UNBOUNDED PRECEDING) as sku\n",
    "                          FROM data_engineer.ams_sf_assets_input a\n",
    "                            ) c\n",
    "                    ON TRIM(UPPER(REPLACE(a.radio_macaddress,':',''))) = c.mac_address\n",
    "\n",
    "                WHERE a.export_date = (SELECT value::date FROM data_engineer.ams_rules_input WHERE rule = 'Rollforward date')\"\"\"\n",
    "data = sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "if len(data) == len(d):\n",
    "    foo = data.merge(d,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "    if len(foo) == 0:\n",
    "        print(\"Both tables are equal!\")\n",
    "    else:\n",
    "        print(\"Both tables are not equal\")\n",
    "else:\n",
    "    print(\"The lenght of each table is different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Validation\n",
    "For validating that every value in the created table is identical to the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test Implementation\n",
    "We ask that you implement at least one unit test to catch errors with your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
